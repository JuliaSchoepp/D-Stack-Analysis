{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d97fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.cloud import language_v2\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import utils as u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542e1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "PROJECT_PATH = \"dstack/d-stack-home\"\n",
    "RAW_PATH = \"data/raw_issues.parquet\"\n",
    "CLEANED_PATH = \"data/cleaned_issues.parquet\"\n",
    "ENRICHED_PATH = \"data/issues_enriched.parquet\"\n",
    "LABELED_PATH = \"data/issues_labeled.parquet\"\n",
    "POSTPROCESSED_PATH = \"data/issues_postprocessed.parquet\"\n",
    "KEYWORDS_PATH = \"keywords_config.txt\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "api_key = os.environ.get(\"API_KEY_GCP\")\n",
    "token_vertex = os.environ.get(\"ACCES_TOKEN_VERTEX\")\n",
    "PROJECT_ID = \"project-8415b93b-4a16-4c2b-901\"\n",
    "LOCATION = \"europe-west3\"\n",
    "print(\"API key loaded:\", bool(api_key))\n",
    "client = language_v2.LanguageServiceClient(client_options={\"api_key\": api_key})\n",
    "\n",
    "keywords_path = Path(KEYWORDS_PATH)\n",
    "\n",
    "LABELS = [\n",
    "    line.strip()\n",
    "    for line in keywords_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    if line.strip() and not line.lstrip().startswith(\"#\")\n",
    "]\n",
    "\n",
    "# some iid s to exclude since they predate the feedback process\n",
    "iids_to_exclude = list(range(1,9))\n",
    "columns_to_keep = [\"iid\", \"title\", \"description\", \"state\", \"created_at\", \"updated_at\", \"closed_at\", \"author_id\", \"author_name\", \"author_state\", \"user_notes_count\", \"upvotes\", \"downvotes\", \"references\"]\n",
    "desc_to_exclude = [\"\", \"test\", \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issues = fetch_all_gitlab_issues(\"dstack/d-stack-home\")\n",
    "# raw_df = pl.DataFrame(issues)\n",
    "# raw_df.write_parquet(RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pl.read_parquet(RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = u.clean_issues_df(raw_df, columns_to_keep, iids_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fbb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = u.prepare_issues_df(df_clean, desc_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39294a2a",
   "metadata": {},
   "source": [
    "## Some analysis of the feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505bd3",
   "metadata": {},
   "source": [
    "- form-generated vs manual issues (anonymous vs non-anonymous feedbackers)\n",
    "- Issues per page \n",
    "- length of issues\n",
    "- temporal analysis - when were issues commited?\n",
    "- sentiment analysis\n",
    "- keyword / label counts: first get the distinct labels, clean them, manually add some more, keyword search them in titles and descriptions\n",
    "- correlations sentiments and labels / topics\n",
    "- correlations between upvotes / downvotes and topics\n",
    "- top comments\n",
    "- Amount of non-content tickets (\"Test\" etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38dc055",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba791cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text_content: str) -> float:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a single string and returns only the float score.\n",
    "    Returns 0.0 if the input is None or the API call fails.\n",
    "    \"\"\"\n",
    "    if text_content is None:\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        # Create the document object\n",
    "        document = language_v2.Document(\n",
    "            content=text_content, \n",
    "            type_=language_v2.Document.Type.PLAIN_TEXT\n",
    "        )\n",
    "\n",
    "        # Call the API\n",
    "        response = client.analyze_sentiment(document=document)\n",
    "        \n",
    "        # Return the sentiment score (-1.0 to +1.0)\n",
    "        return response.document_sentiment.score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text_content[:20]}... Error: {e}\")\n",
    "        return 0.0 # Return a neutral score on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_with_sentiment = df_prepared.with_columns(\n",
    "#     pl.col(\"desc_clean\")\n",
    "#       .map_elements(get_sentiment_score, return_dtype=pl.Float64)\n",
    "#       .alias(\"sentiment\")\n",
    "# )\n",
    "\n",
    "# df_with_sentiment.write_parquet(ENRICHED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment = pl.read_parquet(ENRICHED_PATH)\n",
    "df_with_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699ba27",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d009e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION = (\n",
    "    \"Du bekommst GitLab-Issues aus dem Deutschland-Stack-Konsultationsverfahren. \"\n",
    "    \"Du bist ein Klassifizierungs-Experte. Deine Aufgabe ist es, die Beschreibung zu analysieren \"\n",
    "    \"und sie anhand der Labels in der Liste zu klassifizieren. \"\n",
    "    \"Nutze NUR die zur Verfügung gestellten Labels. Erfinde keine neuen Labels! \"\n",
    "    \"Stelle das Ergebnis als Komma-separierten String zur Verfügung. \"\n",
    "    \"Der String enthält NUR die von dir vergebenen Labels (eins oder bis zu 5). \"\n",
    "    \"Versuche nur so viele Labels wie nötig zu vergeben. \"\n",
    "    \"Wenn kein Label passt, nutze das Label Unklar\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True)\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ffeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_labels(labels_str: str, allowed_labels: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Filtert die durch Komma getrennten Labels und entfernt alle,\n",
    "    die nicht in allowed_labels sind.\n",
    "    \"\"\"\n",
    "    labels = [label.strip() for label in labels_str.split(\",\")]\n",
    "    return [label for label in labels if label in allowed_labels]\n",
    "\n",
    "def classify_issue_multilabel(issue_text: str, labels: list[str]) -> str:\n",
    "    user_prompt = f\"\"\"\n",
    "Labels:\n",
    "{\", \".join(labels)}\n",
    "\n",
    "Issue:\n",
    "{issue_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(text=SYSTEM_INSTRUCTION + \"\\n\\n\" + user_prompt)],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process in batches to handle rate limits and save progress\n",
    "import time\n",
    "\n",
    "batch_size = 10  # Adjust based on rate limits\n",
    "\n",
    "# Check if we have a partial result\n",
    "if Path(LABELED_PATH).exists():\n",
    "    df_labeled = pl.read_parquet(LABELED_PATH)\n",
    "    start_idx = len(df_labeled)\n",
    "else:\n",
    "    df_labeled = df_with_sentiment.clone()\n",
    "    labels_list = [[] for _ in range(len(df_labeled))]\n",
    "    start_idx = 0\n",
    "\n",
    "for i in range(start_idx, len(df_labeled), batch_size):\n",
    "    end_idx = min(i + batch_size, len(df_labeled))\n",
    "    print(f\"Processing batch {i//batch_size + 1}: rows {i} to {end_idx-1}\")\n",
    "\n",
    "    for j in range(end_idx - i):\n",
    "        row_idx = i + j\n",
    "        desc = df_labeled[\"desc_clean\"][row_idx]\n",
    "        try:\n",
    "            labels_str = classify_issue_multilabel(desc, LABELS)\n",
    "            validated_labels = validate_labels(labels_str, LABELS)\n",
    "            labels_list[row_idx] = validated_labels\n",
    "            time.sleep(2)  # Increased sleep to avoid rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {row_idx}: {e}\")\n",
    "            labels_list[row_idx] = []  # Assign empty list on error\n",
    "            time.sleep(5)  # Longer sleep on error\n",
    "\n",
    "    # Update the dataframe with the current labels_list\n",
    "    df_labeled = df_labeled.with_columns(pl.Series(\"labels\", labels_list))\n",
    "\n",
    "    # Save progress\n",
    "    df_labeled.write_parquet(LABELED_PATH)\n",
    "    print(f\"Saved progress after batch {i//batch_size + 1}\")\n",
    "\n",
    "print(\"Labeling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.sample(2).select(\"desc_clean\", \"sentiment\", \"labels\").rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4badbd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labeled.write_parquet(LABELED_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ee7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = pl.read_parquet(LABELED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any labels are empty\n",
    "empty_label_count = df_labeled.filter(pl.col(\"labels\").list.len() == 0).height\n",
    "print(f\"Number of issues with empty labels: {empty_label_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.filter(pl.col(\"labels\").list.len() == 0).select(\"iid\", \"desc_clean\").rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52f828",
   "metadata": {},
   "source": [
    "## Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8573d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postprocessed = pl.read_parquet(POSTPROCESSED_PATH)\n",
    "df_postprocessed = u.postprocess_issues(df_postprocessed)\n",
    "df_postprocessed.write_parquet(POSTPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a5ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
