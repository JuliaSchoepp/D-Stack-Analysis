{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60d97fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.cloud import language_v2\n",
    "from google import genai\n",
    "from google.genai import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "542e1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "PROJECT_PATH = \"dstack/d-stack-home\"\n",
    "RAW_PATH = \"raw_issues.parquet\"\n",
    "CLEANED_PATH = \"cleaned_issues.parquet\"\n",
    "KEYWORDS_PATH = \"keywords_config.txt\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "api_key = os.environ.get(\"API_KEY_GCP\")\n",
    "token_vertex = os.environ.get(\"ACCES_TOKEN_VERTEX\")\n",
    "PROJECT_ID = \"project-8415b93b-4a16-4c2b-901\"\n",
    "LOCATION = \"europe-west3\"\n",
    "print(\"API key loaded:\", bool(api_key))\n",
    "client = language_v2.LanguageServiceClient(client_options={\"api_key\": api_key})\n",
    "\n",
    "keywords_path = Path(KEYWORDS_PATH)\n",
    "\n",
    "LABELS = [\n",
    "    line.strip()\n",
    "    for line in keywords_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    if line.strip() and not line.lstrip().startswith(\"#\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906dfda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_gitlab_issues(\n",
    "    project_path: str,\n",
    "    gitlab_base_url: str = \"https://gitlab.opencode.de\",\n",
    "    per_page: int = 100,\n",
    "    timeout: int = 30,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch all issues from a public GitLab project.\n",
    "\n",
    "    project_path: \"namespace/project\", e.g. \"dstack/d-stack-home\"\n",
    "    returns: list of issue JSON objects\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"Accept\": \"application/json\"})\n",
    "\n",
    "    # URL-encode project path\n",
    "    project_path_enc = project_path.replace(\"/\", \"%2F\")\n",
    "    base_api = f\"{gitlab_base_url}/api/v4/projects/{project_path_enc}/issues\"\n",
    "\n",
    "    issues = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        resp = session.get(\n",
    "            base_api,\n",
    "            params={\n",
    "                \"state\": \"all\",\n",
    "                \"per_page\": per_page,\n",
    "                \"page\": page,\n",
    "                \"order_by\": \"created_at\",\n",
    "                \"sort\": \"asc\",\n",
    "            },\n",
    "            timeout=timeout,\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        batch = resp.json()\n",
    "\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        issues.extend(batch)\n",
    "        page += 1\n",
    "\n",
    "    return issues\n",
    "\n",
    "def load_gitlab_issues(path: str) -> pl.DataFrame:\n",
    "    # load from parquet file\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc58db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issues = fetch_all_gitlab_issues(\"dstack/d-stack-home\")\n",
    "# raw_df = pl.DataFrame(issues)\n",
    "# raw_df.write_parquet(RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dfa6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pl.read_parquet(RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a0c1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some iid s to exclude since they predate the feedback process\n",
    "iids_to_exclude = list(range(1,9))\n",
    "columns_to_keep = [\"iid\", \"title\", \"description\", \"state\", \"created_at\", \"updated_at\", \"closed_at\", \"author_id\", \"author_name\", \"author_state\", \"user_notes_count\", \"upvotes\", \"downvotes\", \"references\"]\n",
    "desc_to_exclude = [\"\", \"test\", \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "523c6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_issues_df(df: pl.DataFrame, columns_to_use: list, rows_to_exclude: list) -> pl.DataFrame:\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"author\").struct.field(\"id\").alias(\"author_id\"),\n",
    "        pl.col(\"author\").struct.field(\"name\").alias(\"author_name\"),\n",
    "        pl.col(\"author\").struct.field(\"state\").alias(\"author_state\"),\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"created_at\").str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S%.fZ\").alias(\"created_at\"),\n",
    "        pl.col(\"updated_at\").str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S%.fZ\").alias(\"updated_at\"),\n",
    "        pl.col(\"closed_at\").str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S%.fZ\").alias(\"closed_at\"),\n",
    "    ])\n",
    "    df = df.filter(~pl.col(\"iid\").is_in(rows_to_exclude))\n",
    "    df = df.unique(subset=[\"title\", \"description\"])\n",
    "    return df.select(columns_to_use)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfde1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_issues_df(df: pl.DataFrame, desc_to_exclude: list) -> pl.DataFrame:\n",
    "    # clean description\n",
    "    df = df.with_columns(\n",
    "        desc_clean = pl.col(\"description\").str.replace_all(\"**Feedback:** <br>\", \"\", literal=True)\n",
    "    )\n",
    "    # get more insights on where issue comes from\n",
    "    df = df.with_columns(\n",
    "        is_from_form = pl.col(\"title\").str.starts_with(\"Feedback für die Seite\"),\n",
    "        form_page = (\n",
    "            pl.when(pl.col(\"title\").str.starts_with(\"Feedback für die Seite\"))\n",
    "            .then(\n",
    "                pl.col(\"title\")\n",
    "                .str.replace(\"^Feedback für die Seite\", \"\")\n",
    "                .str.strip_chars()\n",
    "            )\n",
    "            .otherwise(pl.lit(\"Via OpenCode\"))\n",
    "        )\n",
    "    )\n",
    "    df = df.filter(~pl.col(\"desc_clean\").is_in(desc_to_exclude))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62f895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_issues_df(raw_df, columns_to_keep, iids_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3fbb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enrich_issues_df(df_clean, desc_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0842c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>iid</th><th>title</th><th>description</th><th>state</th><th>created_at</th><th>updated_at</th><th>closed_at</th><th>author_id</th><th>author_name</th><th>author_state</th><th>user_notes_count</th><th>upvotes</th><th>downvotes</th><th>references</th><th>desc_clean</th><th>is_from_form</th><th>form_page</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td><td>datetime[μs]</td><td>datetime[μs]</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>struct[3]</td><td>str</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>343</td><td>&quot;Domäne Sicherheit, Fehlende Th…</td><td>&quot;Die Domäne Sicherheit könnte n…</td><td>&quot;opened&quot;</td><td>2025-11-21 15:13:17.800</td><td>2025-11-21 15:13:17.800</td><td>null</td><td>1654</td><td>&quot;Jürgen Bilberger&quot;</td><td>&quot;active&quot;</td><td>0</td><td>11</td><td>0</td><td>{&quot;#343&quot;,&quot;#343&quot;,&quot;dstack/d-stack-home#343&quot;}</td><td>&quot;Die Domäne Sicherheit könnte n…</td><td>false</td><td>&quot;Via OpenCode&quot;</td></tr><tr><td>278</td><td>&quot;OSBA:&nbsp;&nbsp;Digitale Souveränität&quot;</td><td>&quot;Digitale Souveränität ist eine…</td><td>&quot;opened&quot;</td><td>2025-11-12 10:28:29.695</td><td>2025-11-13 14:54:50.060</td><td>null</td><td>12277</td><td>&quot;Burkhard Noltensmeier&quot;</td><td>&quot;active&quot;</td><td>1</td><td>9</td><td>0</td><td>{&quot;#278&quot;,&quot;#278&quot;,&quot;dstack/d-stack-home#278&quot;}</td><td>&quot;Digitale Souveränität ist eine…</td><td>false</td><td>&quot;Via OpenCode&quot;</td></tr><tr><td>184</td><td>&quot;Ganzheitliche Standardisierung…</td><td>&quot;**Ganzheitliche Standardisieru…</td><td>&quot;opened&quot;</td><td>2025-10-21 15:16:50.085</td><td>2025-12-01 08:49:58.195</td><td>null</td><td>12867</td><td>&quot;Jörg Friebe&quot;</td><td>&quot;active&quot;</td><td>2</td><td>8</td><td>0</td><td>{&quot;#184&quot;,&quot;#184&quot;,&quot;dstack/d-stack-home#184&quot;}</td><td>&quot;**Ganzheitliche Standardisieru…</td><td>false</td><td>&quot;Via OpenCode&quot;</td></tr><tr><td>341</td><td>&quot;Domäne Integration, Observabil…</td><td>&quot;Je nach Scope von &quot;Integration…</td><td>&quot;opened&quot;</td><td>2025-11-21 13:25:57.456</td><td>2025-11-21 13:25:57.456</td><td>null</td><td>13828</td><td>&quot;René Zarwel&quot;</td><td>&quot;active&quot;</td><td>0</td><td>8</td><td>0</td><td>{&quot;#341&quot;,&quot;#341&quot;,&quot;dstack/d-stack-home#341&quot;}</td><td>&quot;Je nach Scope von &quot;Integration…</td><td>false</td><td>&quot;Via OpenCode&quot;</td></tr><tr><td>327</td><td>&quot;Domäne Inbetriebnahme, Empfehl…</td><td>&quot;Die Auswahl der Tools für die …</td><td>&quot;opened&quot;</td><td>2025-11-21 09:12:58.691</td><td>2025-11-24 12:22:32.449</td><td>null</td><td>26</td><td>&quot;Dirk Gernhardt&quot;</td><td>&quot;active&quot;</td><td>1</td><td>8</td><td>0</td><td>{&quot;#327&quot;,&quot;#327&quot;,&quot;dstack/d-stack-home#327&quot;}</td><td>&quot;Die Auswahl der Tools für die …</td><td>false</td><td>&quot;Via OpenCode&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 17)\n",
       "┌─────┬─────────────┬─────────────┬────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ iid ┆ title       ┆ description ┆ state  ┆ … ┆ references ┆ desc_clean ┆ is_from_fo ┆ form_page  │\n",
       "│ --- ┆ ---         ┆ ---         ┆ ---    ┆   ┆ ---        ┆ ---        ┆ rm         ┆ ---        │\n",
       "│ i64 ┆ str         ┆ str         ┆ str    ┆   ┆ struct[3]  ┆ str        ┆ ---        ┆ str        │\n",
       "│     ┆             ┆             ┆        ┆   ┆            ┆            ┆ bool       ┆            │\n",
       "╞═════╪═════════════╪═════════════╪════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 343 ┆ Domäne      ┆ Die Domäne  ┆ opened ┆ … ┆ {\"#343\",\"# ┆ Die Domäne ┆ false      ┆ Via        │\n",
       "│     ┆ Sicherheit, ┆ Sicherheit  ┆        ┆   ┆ 343\",\"dsta ┆ Sicherheit ┆            ┆ OpenCode   │\n",
       "│     ┆ Fehlende    ┆ könnte n…   ┆        ┆   ┆ ck/d-stack ┆ könnte n…  ┆            ┆            │\n",
       "│     ┆ Th…         ┆             ┆        ┆   ┆ …          ┆            ┆            ┆            │\n",
       "│ 278 ┆ OSBA:       ┆ Digitale    ┆ opened ┆ … ┆ {\"#278\",\"# ┆ Digitale   ┆ false      ┆ Via        │\n",
       "│     ┆ Digitale    ┆ Souveränitä ┆        ┆   ┆ 278\",\"dsta ┆ Souveränit ┆            ┆ OpenCode   │\n",
       "│     ┆ Souveränitä ┆ t ist eine… ┆        ┆   ┆ ck/d-stack ┆ ät ist     ┆            ┆            │\n",
       "│     ┆ t           ┆             ┆        ┆   ┆ …          ┆ eine…      ┆            ┆            │\n",
       "│ 184 ┆ Ganzheitlic ┆ **Ganzheitl ┆ opened ┆ … ┆ {\"#184\",\"# ┆ **Ganzheit ┆ false      ┆ Via        │\n",
       "│     ┆ he Standard ┆ iche Standa ┆        ┆   ┆ 184\",\"dsta ┆ liche Stan ┆            ┆ OpenCode   │\n",
       "│     ┆ isierung…   ┆ rdisieru…   ┆        ┆   ┆ ck/d-stack ┆ dardisieru ┆            ┆            │\n",
       "│     ┆             ┆             ┆        ┆   ┆ …          ┆ …          ┆            ┆            │\n",
       "│ 341 ┆ Domäne Inte ┆ Je nach     ┆ opened ┆ … ┆ {\"#341\",\"# ┆ Je nach    ┆ false      ┆ Via        │\n",
       "│     ┆ gration,    ┆ Scope von   ┆        ┆   ┆ 341\",\"dsta ┆ Scope von  ┆            ┆ OpenCode   │\n",
       "│     ┆ Observabil… ┆ \"Integratio ┆        ┆   ┆ ck/d-stack ┆ \"Integrati ┆            ┆            │\n",
       "│     ┆             ┆ n…          ┆        ┆   ┆ …          ┆ on…        ┆            ┆            │\n",
       "│ 327 ┆ Domäne Inbe ┆ Die Auswahl ┆ opened ┆ … ┆ {\"#327\",\"# ┆ Die        ┆ false      ┆ Via        │\n",
       "│     ┆ triebnahme, ┆ der Tools   ┆        ┆   ┆ 327\",\"dsta ┆ Auswahl    ┆            ┆ OpenCode   │\n",
       "│     ┆ Empfehl…    ┆ für die …   ┆        ┆   ┆ ck/d-stack ┆ der Tools  ┆            ┆            │\n",
       "│     ┆             ┆             ┆        ┆   ┆ …          ┆ für die …  ┆            ┆            │\n",
       "└─────┴─────────────┴─────────────┴────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort(by=\"upvotes\", descending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e02a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts_df = (\n",
    "    df\n",
    "    .group_by(\n",
    "        pl.col(\"created_at\").dt.date().alias(\"date\")\n",
    "    )\n",
    "    .len()\n",
    "    .rename({\"len\": \"count\"})\n",
    "    .sort(\"date\")\n",
    ")\n",
    "\n",
    "chart = (\n",
    "    daily_counts_df\n",
    "    .plot.line(\n",
    "        x=\"date\",       # Explicitly set the X-axis\n",
    "        y=\"count\",      # Explicitly set the Y-axis\n",
    "        # title=\"Daily Activity\" # Set a title\n",
    "    )\n",
    "    .properties(width=500)\n",
    "    # Altair chart configurations can be chained\n",
    "    .configure_axisY(title=\"Count of Records\")\n",
    ")\n",
    "\n",
    "# chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39294a2a",
   "metadata": {},
   "source": [
    "## Some analysis of the feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505bd3",
   "metadata": {},
   "source": [
    "- distinct feedbackers\n",
    "- form-generated vs manual issues (anonymous vs non-anonymous feedbackers)\n",
    "- Issues per page \n",
    "- length of issues\n",
    "- temporal analysis - when were issues commited?\n",
    "- sentiment analysis\n",
    "- keyword / label counts: first get the distinct labels, clean them, manually add some more, keyword search them in titles and descriptions\n",
    "- correlations sentiments and labels / topics\n",
    "- correlations between upvotes / downvotes and topics\n",
    "- top comments\n",
    "- Amount of non-content tickets (\"Test\" etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38dc055",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba791cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text_content: str) -> float:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a single string and returns only the float score.\n",
    "    Returns 0.0 if the input is None or the API call fails.\n",
    "    \"\"\"\n",
    "    if text_content is None:\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        # Create the document object\n",
    "        document = language_v2.Document(\n",
    "            content=text_content, \n",
    "            type_=language_v2.Document.Type.PLAIN_TEXT\n",
    "        )\n",
    "\n",
    "        # Call the API\n",
    "        response = client.analyze_sentiment(document=document)\n",
    "        \n",
    "        # Return the sentiment score (-1.0 to +1.0)\n",
    "        return response.document_sentiment.score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text_content[:20]}... Error: {e}\")\n",
    "        return 0.0 # Return a neutral score on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_with_sentiment = df.with_columns(\n",
    "#     pl.col(\"desc_clean\")\n",
    "#       .map_elements(get_sentiment_score, return_dtype=pl.Float64)\n",
    "#       .alias(\"sentiment\")\n",
    "# )\n",
    "\n",
    "# df_with_sentiment.write_parquet(\"enriched_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1fe90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment = pl.read_parquet(\"enriched_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75617a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('**Für digitale Verwaltung bedarf es EINES Nachschlageortes und EINES Ortes der Wahrheit für Themen der digitalen Verwaltung**\\n\\nInformation:\\nDas BMDS strebt an, die bisherigen Glossare im Umfeld\\n\\n1. https://docs.fitko.de/fit/fit-sb/glossary/ \\n2. https://docs.fitko.de/fit/glossary/ \\n3. https://docs.fitko.de/fit-connect/docs/glossary/ \\n\\nzu konsolidieren und auch für den Deutschland-Stack zu nutzen.\\n\\nAls Anforderung zumindest für den Deutschland-Stack, aber **idealerweise auch für digitale Verwaltung insgesamt ** ist:\\n1. EINE verbindliche Begriffsdefinition\\n2. EIN Ort der Wahrheit für Fach- und technische Fragen\\n3. Hierfür bedarf es einer Governance, die frei von Hierarchie und ohne Wasserfall funktioneriert.\\n4. Ähnlich wie für die Standardfabrik empfehle ich ein knappes verbindliches Regelwerk, das orientiert an den Vorgaben für open standard angelegt ist.\\n\\nErläuterung \\nEin Nachschlagewerk sollte - gerade um in der föderalen Verwaltungsstruktur Deutschlands zu wirken - nicht als Macht- oder Vorgabeinstrument funktionieren, sondern auch das Herausarbeiten von unterschiedlichen Sichtweisen und perspektivisch die Auflösung von Auffassungsunterschieden konvergent hin zu einer gemeinsamen Sicht unterstützen.\\n\\nInsofern sind verbindliche Regeln für den Prozess der Erarbeitung und Pflege eines Wissensmanagements für digitale Verwaltung unerlässlich.\\nAuch bedarf es einer Instanz, die die verbindlichen Regeln durchsetzen kann. \\nUm hier ein Durschlagen von Hierarchie und Wasserfall zu vermeiden, sollte diese Aufgabe nicht einem Beteiligten wie dem BMDS zugedacht werden.\\n\\nDie FITKO erscheint auch nur bedingt geeignet, da sie bisher die erforderliche Stringenz und den gebotenen Dienstleistungscharakter gegenüber der kommunalen Ebene vermissen lässt. Die Ursache hierfür dürfte in der Zuordnung zum IT-Planungsrat liegen, bei dem die kommunale Ebene nicht adäquat berücksichtigt ist.\\n\\nUpdate 27.10.2025: Inzwischen gibt es ein Glossar unter https://deutschland-stack.gov.de/glossar/ \\nDieses Glossar ist rudimentär und es ist nicht kooperativ angelegt, sondern hierarchisch. Insofern bleibt die deutlich weiter gefasste Anforderung bestehen. Erfüllt würde die Anforderung durch ein Wiki mit offenem Beteilgungsprozess und festen Regeln hierfür.\\n\\nIm Zusammenhang mit\\nhttps://gitlab.opencode.de/dstack/d-stack-home/-/issues/152\\nhttps://gitlab.opencode.de/dstack/d-stack-home/-/issues/153\\nhttps://gitlab.opencode.de/dstack/d-stack-home/-/issues/176\\nhttps://gitlab.opencode.de/dstack/d-stack-home/-/issues/178\\nhttps://gitlab.opencode.de/dstack/d-stack-home/-/issues/180\\n\\n**Unmittelbar verbunden mit https://gitlab.opencode.de/dstack/d-stack-home/-/issues/216**\\nDort ergänzt:\\nDie Definition des Standards ist falsch. Orientierung bietet https://www.it-business.de/was-ist-ein-standard-a-ebd714a30ec1712cfd36813c09c0240f/ oder der Wikipedia-Artikel. Ein Standard kann in der IT und beim Deutschland-Stack vielfältige, grundlegend unterschiedliche Inhalte haben. Um hier grundlegende Missverständnisse und Unklarheiten zu vermeiden, muss klar benannt werden, welche Art von Standard gemeint ist (Datenstandard, Standard-Funktionalität, Software-Standard (funktional oder technisch).\\n\\n___\\nEine Idee für die erforderlichen Grundlagen ist ableitbar aus https://opcfoundation.org/about/what-is-opc/',\n",
       "  -0.08399999886751175),\n",
       " ('Tippfehler: \"verlässlich, souverän und sicheren\" ⇒ sicher',\n",
       "  0.29100000858306885),\n",
       " ('Bei den Kriterien für Open Source Produkte fehlt aus meiner Sicht eine Einordnung der angewandten Lizenz für den kommerziellen Gebrauch.\\n1. Die Lizenz sollte auch ein Hosting durch Dritte erlauben, damit Unternehmen von beliebigen (europäischen und auch kleineren lokalen) Hostinganbietern die entsprechende Software einkaufen können und kein eigenes Hosting-KnowHow aufbauen müssen.\\n\\n2. Müssen die Open Source Produkte im Stack wohl tiefergehend betrachtet werden. Die steigende Tendenz, Produkte als Open Source zu starten und dann zu kostenpflichtigen Enterprise Versionen auszubauen, macht das notwendig. In der offenen Version fehlen dann wichtige Security- und Enterprise-Funktionalitäten, wie Single Sign On, Zugriff auf Auth-Provider usw.\\n\\nDiese beiden Punkte sind \"moving targets\". Müssen also dauernd beobachtet werden.',\n",
       "  -0.257999986410141),\n",
       " ('Ich möchte anregen, den Deutschland Stack um das W3C DPV zu erweitern. \\nDas DPV- Data Privacy Vocabulary ist ein sehr hilfreiches Vokabular, um Datenschutzprozesse maschinenlesbar&nachvollziehbar zu beschreiben – gerade im Kontext der DSGVO und nationaler Gesetze wie dem Bundesdatenschutzgesetz (BDSG).\\n (z. B. Art. 5, 6, 30 DSGVO).  DPV-Projekt: https://w3c.github.io/dpv/2.2/dpv/\\nz.B. Durch die Nutzung von DPV in einer App wird erstmals möglich, dass Datenschutzinformationen automatisch verstanden, überprüft und ausgetauscht werden können – z. B. zwischen App, Backend, Partnern oder Aufsichtsbehörden –, sodass Transparenz, Compliance-Prüfung und Einwilligungsverwaltung maschinell erfolgen können, statt nur manuell in Textform.',\n",
       "  0.11400000005960464),\n",
       " ('Die beiden verlinkten Grafikten auf https://technologie.deutschland-stack.gov.de/ Datalab und Finanziert von der Europäischen Union funktionieren nicht. Auch funktioniert die Angegebene OpenCode Seite im Footer auch nicht. https://gitlab.opencode.de/dstack/techstack-landkarte hier erscheint nur eine 404',\n",
       "  -0.8889999985694885),\n",
       " ('## Worum geht es?\\nDie Technologie-Landkarte (https://technologie.deutschland-stack.gov.de/) ist in der aktuellen Form ein bunter Blumenstrauß an Technologien und Standards, aus denen sich aber keine skalierbare, sichere und betreibbare Anwendung bzw. auch nur Komponenten dafür erzeugen ließen. \\n\\nDa die Landkarte aber für viele Beschaffer*innen und Mitarbeitende von Verwaltung und Wirtschaft in gewisser Weise normative Kraft erreichen könnte, ist zur Definition der Anspruchshaltung an eine technische Umsetzung die Aufnahme weiterer Aspekte sinnvoll (sofern die Landkarte in der Form weiter verwendet werden soll).\\n\\n## Was kann daran verbessert werden?\\nBeispielhaft am Betrieb sei am Beispiel GA-Lotse und der Erfahrung mit anderen Infrastrukturen ähnlicher Größe auf folgende fehlende Aspekte mit beispielhaften Technologien und Standards hingewiesen:\\n\\n### Für die sichere Entwicklung notwendige Aspekte, die bisher fehlen\\n\\n#### Fehlen von IAM-Lösungen und Autentication Standards sowie fehlende Priorisierung von Phishing-Resistenz\\nLösungen wie Keycloak (https://www.keycloak.org/) als etablierte IAM-Lösungen fehlen vollständig. Authentication Standards wie Passkeys oder WebAuthn (https://www.w3.org/press-releases/2019/webauthn/) sind als konfigurierabre, inzwischen gut in Browser und Endgeräte integrierte Standards aufzunehmen, um etwa FIDO-Tokens oder andere passwortlose, phishing-resistente Loginverfahren stackübergreifend zu etablieren. Für einen Stack, der für 2028 angekündigt wird, sollte durchgängige phishing-resistente Anmeldung schon eine Kernanforderung sein.\\n\\n#### Fehlen von Standards zur Workload Identifikation\\nStandards wie SPIFFE / SPIRE (https://spiffe.io/) sind anzustreben, um Workloads in verteilten Umgebungen sicher identifizieren und attestieren zu können.\\n\\n#### Fehlen von weiteren Testingframeworks für andere Zwecke als Browsertests\\nMit der Nennung von Selenium wird immerhin der Anspruch an automatisiertes Testen von Bestandteilen angedeutet.\\nUm die Erwartungshaltung hier richtig zu setzen, sind aber die folgenden Aspekte zumindest zu benennen mit beispielhaften Tools:\\n- Verwendung von Unit-Tests in der Entwicklung (z.B. im Bereich Java über Junit https://junit.org/)\\n- Verwendung von Integrationtests, auch von verteilten Umgebungen mit echten Containern (z.B. über Frameworks wie Testcontainers https://testcontainers.com/)\\n- Verwendung von automatisierten Browser Ende-zu-Ende-Tests (z.B. über Playwright https://playwright.dev/)\\n\\n#### Fehlen von Tooling, um die Belastbarkeit von Komponenten zu validieren\\nTools für Lasttests (z.B. k6 https://k6.io/) sowie für das gezielte Herbeiführen von Ausfällen oder verminderter Servicequalität (Chaos Engineering, z.B. https://chaos-mesh.org/) sind aufzunehmen, um bereits im Entwicklungsprozess die Belastbarkeit von Komponenten zu validieren.\\n\\n#### Aufnahme von automatisierbaren Barrierefreiheitschecks\\nBarrierefreiheit ist ein Thema, dass sich mit individuell menschlichen Bedürfnissen auseinandersetzt und ist nur bis zu einem gewissen Teil automatisiert lösbar. Dennoch ist die Aufnahme von A11Y-Scannern wie Axe (https://www.npmjs.com/package/@axe-core/cli) sinnvoll, um im Entwicklungsprozess zumindest Regressionen schneller zu erkennen.\\n\\n#### Aufnahme von Komponenten zur Beibehaltung hoher Codequalität\\nSAST-Tools wie SonarQube (https://www.sonarsource.com/de/products/sonarqube/) sowie Code Formater / Linter wie Spotless (https://github.com/diffplug/spotless) sollten in der Genese von Anwendungen entsprechend berücksichtigt werden.\\n\\n#### Fehlen von guten Dokumentationsgrundlagen\\nNeben der technischen Excellenz sollte auch die Dokumentation von hoher Qualität sind. Dabei helfen Frameworks wie arc42 (https://arc42.org/) sowie Architecture Decision Records (https://docs.arc42.org/section-9/), die dabei helfen, bestimmte Entscheidungen nachzuvollziehen.\\n\\n### Für sicheren und skalierbaren Betireb notwendige Aspekte, die bisher fehlen\\n\\n#### Handling von Zertifikaten für M2M in Infrastrukturen der angestrebten Größe\\nOhne weitestgehende Automatisierung des Zertifikationshandlings der Maschinen-zu-Maschinen-Kommunikation wird eine Infastruktur in der Größe des D-Stack nicht kontinuierlich betreibbar sein. Standards wie ACME (https://www.rfc-editor.org/rfc/rfc8555) in Kombination mit Komponenten wie dem CertManager (https://cert-manager.io/) sind hier unerlässlich.\\n\\n#### Fehlen von Policy- / Admission-Controllern zum Durchsetzen von Rahmenbedingungen im Betrieb\\nAdmission Controller wie Kyverno (https://kyverno.io/) im Kubernetesumfeld oder Open Policy Agent (https://www.openpolicyagent.org/) für andere Umgebungen sind unerlässlich, um in verteilten Umgebungen gemeinsame Policies für den Betrieb durchzusetzen.\\n\\n#### Fehlen von Image Integrity Frameworks für die Supply Chain\\nLösungen wie Sigstore (https://www.sigstore.dev/) zur Sicherstellung der Integrität von Softwarebestandteilen sind in Kombination mit Admissioncontrollern durchzusetzen, um Images sicher zu beziehen und zu starten. Ein hohes Level an Supply Chain Security nach dem SLSA Framework (https://slsa.dev/) ist anzustreben.\\n\\n#### Fehlen von Tooling und Standards zur Inventarisierung und Überwachung von Supply Chains\\nStandards wie SBOMs, etwa als Teil der Anforderungen an die Cyber-Resilienz (vgl. BSI TR-03183 https://www.bsi.bund.de/DE/Themen/Unternehmen-und-Organisationen/Standards-und-Zertifizierung/Technische-Richtlinien/TR-nach-Thema-sortiert/tr03183/TR-03183_node.html) fehlen. Darauf aufbauend fehlen Formatstandards und Tooling zum Umgang mit Vulnerabilities wie DependencyTrack (https://dependencytrack.org/) oder DevGuard (https://opencode.de/de/aktuelles/sicherheit-im-entwicklungsalltag-verankern-mit-devguard-5300).\\n\\n#### Fehlen von Tooling zur Observability und Monitoring sowie zur Log Aggregation\\nTooling wie Grafana, Grafana Loki (https://grafana.com/) oder Prometheus (https://prometheus.io/) fehlt vollständig.\\n\\n## Erfahrungen und mögliche Interessenskonflikte der beitragenden Person in Bezug auf den Konsultationsgegenstand\\nBianca Kastl ist aktuell beruflich Product Owner für das Gesundheitsamt der Stadt Frankfurt am Main und technisch hauptverantwortlich für die Fachanwendungsplattform [GA-Lotse](https://ga-lotse.de/) mit dem Schwerpunkt auf Gesundheitsämtern. Die Umsetzung ist ein Kooperationsprojekt des Hessischen Ministeriums für Familie, Senioren, Sport, Gesundheit und Pflege mit dem Gesundheitsamt Frankfurt unter der EU-Förderung NextGenerationEU. Das Budget liegt bei über 24 Millionen Euro.\\nGA-Lotse ist nach Stand der Technik umgesetzt, cloud native, konsequent nach Zero Trust umgesetzt und verfolgt in der Entwicklung einen konsequenten DevSecOps-Ansatz. Die Plattform wird aktuell in 12 von 24 Kommunen in Hessen seit mehr als einem Jahr betrieben und hat bereits aktive Nachnutzung im Sinne von Ko-Kreation der Plattform-Komponenten in vier Kommunen in Schleswig-Holstein. GA-Lotse ist mehrfach ausgezeichnet in den Disziplinen IT-Security, Open Source und Nutzerzentrierung ([InfoSec Impact Award](https://www.behoerden-spiegel.de/2025/03/28/infosec-impact-awards-2025-vergeben/), [Finalist Open Source Wettbewerb](https://open-source-wettbewerb.de/voting/), OpenCoDE Top 20 Oktober 2025, [Preis für gute Verwaltung 2025](https://frankfurt.de/de-de/aktuelle-meldung/meldungen/ga-lotse-erhaelt-preis-fuer-gute-verwaltung-2025/)). GA-Lotse ist als Open Source auf [OpenCoDE](https://opencode.de/de/software/ga-lotse-3352) verfügbar und entsprechend nachnutzbar.\\n\\nZivilgesellschaftlich ist sie 1. Vorsitzende des Innovationsverbund Öffentliche Gesundheit e.V. und engagiert sich für eine bessere Digitalisierung von Verwaltung und Gesundheitswesen in Deutschland. Sie war dabei in den letzten Jahren mehrfach zu Themen der Digitalisierung in Gesundheitswesen und Verwaltung als Sachverständige geladen ([OZG 2.0](https://www.bundestag.de/resource/blob/970002/20-4-303-A.pdf), [Gesundheitsdatennutzungsgesetz](https://www.bundestag.de/resource/blob/977258/20_14_0165-11-_Innovationsverbund-oeffentliche-Gesundheit-Bianca-Kastl_GDNG.pdf), [Open Source](https://www.bundestag.de/resource/blob/1032152/Stellungnahme-Kastl.pdf)).\\n\\nIhr fachlicher Schwerpunkt sind skalierende, sichere digitale Infrastrukturen,\\nSystemarchitekturen, Cloud native Anwendungen, IT-Security mit dem Fokus auf Zero Trust\\nPrinzipien, Privacy sowie Barrierefreiheit und User Experience, seit Jahren in Open Source.\\n\\nFür den InÖG hat sie in der Pandemie [IRIS connect](https://www.iris-connect.de/), eine Open Source Kommunikationsinfrastruktur im öffentlichen Gesundheitsdienst, als Betriebsverantwortliche von 2021 bis 2022 an begleitet. Die Betriebsverantwortung umfasste dabei 54 von 116 möglichen Ämter in NRW, Hessen, Thüringen und Sachsen in einem sehr heterogenen Betriebsszenario von SaaS für ganze Bundesländer zu On-Premises Selfhosting in einzelnen Kommunen.',\n",
       "  -0.19699999690055847),\n",
       " ('Guten Tag und vielen Dank für die Möglichkeit, Feedback für die Entwicklung des Deutschland-Stacks zu geben.\\n\\nDie Aufnahme von Mastodon in den Deutschland-Stack stellt einen wichtigen Schritt zur Förderung einer digital souveränen Kommunikation mit der Gesellschaft dar. Im Koalitionsvertrag der Bundesregierung (2025) ist festgehalten, dass die Gesellschaft „digital kompetent, selbstbestimmt und inklusiv“ sein soll, wobei insbesondere die „Resilienz unserer Gesellschaft“ sowie die „Wehrhaftigkeit unserer Demokratie“ (Z. 2225-2226) als zentrale Ziele hervorgehoben werden.\\n\\nMastodon als föderiertes, dezentrales und datenschutzorientiertes soziales Netzwerk unterstützt diese Ziele auf vielfältige Weise:\\n\\n1. **Digitale Souveränität und Selbstbestimmung:**\\\\\\n   Durch den Einsatz von Mastodon wird die Abhängigkeit von globalen, zentralisierten Plattformen reduziert.\\n2. **Stärkung der gesellschaftlichen Resilienz und demokratischen Wehrhaftigkeit:**\\\\\\n   Mastodons dezentrale Struktur macht das Netzwerk weniger anfällig für Manipulation, Überwachung oder Zensur durch einzelne Akteure. Dies stärkt die demokratische Teilhabe und schützt vor der Verbreitung von Desinformation, wodurch die gesellschaftliche Resilienz gegenüber digitalen Angriffen erhöht wird.\\n3. **Förderung von Inklusion und digitaler Kompetenz:**\\\\\\n   Als offene Plattform bietet Mastodon vielfältige Möglichkeiten für unterschiedliche gesellschaftliche Gruppen, sich digital zu vernetzen und zu partizipieren. Die Plattform fördert damit eine inklusive Kommunikationskultur, die im Sinne des Koalitionsvertrags essenziell ist.\\n4. **Open Source als Grundlage für Transparenz und Anpassungsfähigkeit:**\\\\\\n   Mastodon ist eine Open-Source-Software, die kontinuierlich von einer weltweiten Community weiterentwickelt wird. Diese Offenheit ermöglicht nicht nur hohe Transparenz und Nachvollziehbarkeit des Quellcodes, sondern auch eine flexible Anpassung an spezifische Anforderungen der deutschen Gesellschaft und Verwaltung. Open Source ist somit ein Schlüssel zur Unabhängigkeit von proprietären Lösungen und zur Sicherstellung langfristiger Kontrolle und Weiterentwicklung.\\n\\nDie Bundesregierung ist bereits auf Mastodon vertreten (https://social.bund.de/). Allerdings stellen nicht alle Länder eine Mastodon-Instanz für die eigene Nutzung und die Nutzung durch Kommunen bereit. Durch die Aufnahme von Mastodon als Basiskomponente kann die Nutzung in Ländern und Kommunen gestärkt werden.',\n",
       "  0.3059999942779541),\n",
       " (\"Die Erlang Ecosystem Foundation (EEF)(erlef.org) plädiert für die Inklusion der Programmiersprache 'Elixir' in der Kategorie 'Entwicklung'. Siehe: https://de.wikipedia.org/wiki/Elixir_(Programmiersprache). Elixir wird hauptsächtlich in Europa (im Baltikum) gepflegt und weiter entwickelt.\",\n",
       "  0.05400000140070915),\n",
       " ('Entfernen von veralteten Sicherheitstechnologien. Aktuell wird 3DES und SHA gelistet. Dabei wird bei 3DES auch auf eine BSI TR verlinkt welche 3DES mit *keinem* Wort erwähnt. HTTP wird gelistet aber HTTPS nicht.\\n3DES und SHA(1) sollte natürlich nicht Teil eines modernen Tech-Stacks sein.  HTTP sollte nur begrenzt eingesetzt werden.\\nWarum wird hier das BSI nicht mit einbezogen um Empfehlungen zu geben oder zumindest den Tech-Stack zu prüfen?',\n",
       "  -0.46000000834465027),\n",
       " ('Die vorliegende Konzeption des Deutschland-Stacks weist signifikante Mängel in der strategischen Zielsetzung und der technologischen Kohärenz auf. Es bleibt unklar, ob die Intention primär die Konsolidierung und das Hosting bestehender Altanwendungen ist oder ob eine zukunftsweisende Architektur für Cloud-Native-Entwicklungen etabliert werden soll.\\nDie Auswahl der Frameworks erscheint in weiten Teilen als Bestandsaufnahme und nicht als Ergebnis einer stringenten Architekturentscheidung. Die Aufnahme obsolet gewordener Technologien wie Jenkins, Spinnaker, FTPS, CouchDB, Docker Swarm und Nomad ist unverständlich. Deren Einsatz für Neuentwicklungen würde den Stack bereits beim Launch zu einem Migrationshemmnis deklarieren, da diese Werkzeuge von zeitgemäßen Architekten nicht mehr als Standard gesetzt werden.\\nEs manifestiert sich ein Mangel an architektonischer Durchgängigkeit und es existieren erhebliche Lücken (White Spots), insbesondere im Hinblick auf moderne, agenten-basierte und State-of-the-Art Cloud-Native-Anwendungen. Die Konzentration auf spezifische Frameworks geht zu Lasten der Einhaltung und Definition grundlegender Standards. Im Bereich der Datenarchitektur und Interoperabilität ist die Beschränkung auf RDF und DCAT für die Semantik unzureichend und deutet auf eine mangelnde Fachexpertise in dieser Domäne hin.\\nEine strukturierte Kategorisierung nach Architekturdomänen (z.B. Daten, Sicherheit, Infrastruktur) mit einer klaren Ableitung der notwendigen Standards und darauf aufbauenden Frameworks ist nicht vorhanden. Der aktuelle Stack ist primär auf klassische Web-Applikationen ausgerichtet und vernachlässigt andere essenzielle Architekturmuster.\\nWesentliche, applikationsübergreifende Aspekte wie fachliche Protokollierung, Auditing, Task-Management (Task-Based Architecture) sowie die explizite Formulierung der Cloud Native Principles und deren Abbildung im Stack fehlen.\\nDie Definition von OIDC allein ist im Kontext eines föderalen Staates irrelevant. Eine funktionale, dezentrale Identitätsverwaltung (IDM), die mit Initiativen wie EUDI und EUBW kompatibel ist, erfordert die Integration von Standards wie DID, VC, OIDC4VC, SDJWR und JSON-LD, welche nicht berücksichtigt wurden. Die Auflistung potenziell veralteter Frameworks birgt das Risiko, unerfahrene Architekten fehlzuleiten, weshalb eine Überprüfung und Eliminierung dieser Komponenten dringend erforderlich ist.\\nZukünftige Entwicklungen im Bereich der KI-gestützten Softwaregenerierung werden Applikations-Frameworks marginalisieren und die Bedeutung von Plattform-Frameworks (wie K8S, ISTIO, Serverless, Eventing und agentic task-based frameworks) exponentiell steigern.\\nDie Auswahl der Komponenten scheint nicht auf einer breiten Konsultation aller relevanten Domänenexperten (z.B. Daten-, Security- und Identity/Trust-Architekten) zu basieren, sondern wurde möglicherweise durch die am stärksten artikulierten Beiträge definiert. Es fehlt die Begründung und Spezifikation des Einsatzzweckes jedes einzelnen Elements (Produkt, Standard, Framework). Die reine listenbasierte Zusammenstellung von Frameworks ist ein Ansatz, der sich bereits in früheren Projekten (analog zu SAGA) als nicht tragfähig erwiesen hat.\\nAbschließend wird postuliert, dass der Stack idealerweise nur Frameworks umfassen sollte, bei deren Entwicklung die öffentliche Hand aktiv mitgestaltend tätig ist, um die notwendige technologische Souveränität zu gewährleisten. Eine Referenzierung von lediglich in GIT-Repositories verfügbaren Lösungen ohne Governance ist als fahrlässig zu bewerten.\\nSoll ich Ihnen eine Zusammenfassung dieser Punkte für eine Präsentation erstellen?Der Stärker gewinnt.',\n",
       "  -0.5170000195503235)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_sentiment.sort(by=\"sentiment\").sample(10).select(\"desc_clean\", \"sentiment\").rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699ba27",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d009e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7ab82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION = (\n",
    "    \"Du bekommst GitLab-Issues aus dem Deutschland-Stack-Konsultationsverfahren. \"\n",
    "    \"Du bist ein Klassifizierungs-Experte. Deine Aufgabe ist es, die Beschreibung zu analysieren \"\n",
    "    \"und sie anhand der Labels in der Liste zu klassifizieren. \"\n",
    "    \"Nutze NUR die zur Verfügung gestellten Labels. Erfinde keine neuen Labels! \"\n",
    "    \"Stelle das Ergebnis als Komma-separierten String zur Verfügung. \"\n",
    "    \"Der String enthält NUR die von dir vergebenen Labels (eins oder bis zu 5).\"\n",
    "    \"Wenn kein Label passt, nutze das Label Unklar\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee0bc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True)\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "518ffeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_labels(labels_str: str, allowed_labels: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Filtert die durch Komma getrennten Labels und entfernt alle,\n",
    "    die nicht in allowed_labels sind.\n",
    "    \"\"\"\n",
    "    labels = [label.strip() for label in labels_str.split(\",\")]\n",
    "    return [label for label in labels if label in allowed_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a1e32036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_issue_multilabel(issue_text: str, labels: list[str]) -> str:\n",
    "    user_prompt = f\"\"\"\n",
    "Labels:\n",
    "{\", \".join(labels)}\n",
    "\n",
    "Issue:\n",
    "{issue_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(text=SYSTEM_INSTRUCTION + \"\\n\\n\" + user_prompt)],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "681136c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_with_sentiment.sample(3).with_columns(\n",
    "    pl.col(\"desc_clean\")\n",
    "    .map_elements(\n",
    "        lambda text: validate_labels(\n",
    "            classify_issue_multilabel(text, LABELS),\n",
    "            LABELS,\n",
    "        ),\n",
    "        return_dtype=pl.List(pl.Utf8),\n",
    "    )\n",
    "    .alias(\"labels\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d83a7742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bei der Inbetriebnahme sind normalerweise mehrere Automatisierungstools im Einsatz. Für den Zugriff eines Tools auf ein anderes oder zur Installation einer Anwendung in die Betriebsumgebung werden üblicherweise Tokens benötigt. Diese Tokens müssen konfiguriert und ausgetauscht werden. Tokens kommen auch bei Zugriffen einer Anwendung auf Schnittstellen einer anderen Anwendung zum Einsatz. Zur Verwaltung der Tokens werden ist es insbesondere bei einer hohen Anzahl von Tokens sinnvoll, Secretmanagement Tools wie z.B. die folgenden einzusetzen:\\n\\n* OpenBao (https://openbao.org/, Mozilla Public License, version 2.0)\\n* Infisical (https://infisical.com/, MIT expat license)',\n",
       "  0.007000000216066837,\n",
       "  ['Betrieb', 'Infrastruktur', 'Sicherheit', 'Toolvorschlag']),\n",
       " ('Die Inbetriebnahme sollte so gut wie möglich automatisiert ablaufen. Vorherige Prüfungen wie die Durchführung automatisierter Tests, Einhaltung von Programmierrichtlinien oder Security Checks sind dabei Standard. Im folgenden eine Auswahl an Tools für die Automatisierung des Inbetriebnahme-Prozesses:\\n\\n* Security Scanning z.B.\\n  * Renovate (https://github.com/renovatebot/renovate, GNU Affero General Public License v3.0)\\n  * Dependabot (https://github.com/dependabot/, MIT Lizenz)\\n  * Trivy (https://www.aquasec.com/products/trivy/, https://github.com/aquasecurity/trivy, Apache 2 Lizenz)\\n  * OWASP Dependency Check (https://owasp.org/www-project-dependency-check/, Apache 2 Lizenz)\\n  * Sonarqube (https://www.sonarsource.com/, LGPLv3)\\n* Linting z.B.\\n  * eslint (https://github.com/eslint/eslint, MIT License)\\n* Testautomatisierung z.B.\\n  * Selenium (https://www.selenium.dev/, Apache 2.0 license)\\n  * Robot Framework (https://robotframework.org/, Apache 2.0 license)\\n  * Cypress (https://github.com/cypress-io/cypress, MIT License)',\n",
       "  0.06300000101327896,\n",
       "  ['Betrieb', 'Entwicklung', 'Sicherheit', 'Toolvorschlag', 'Open Source']),\n",
       " ('Liebes Deutschland-Stack-Team,\\nich verfolge das Projekt mit Spannung und Vorfreude. Mir fehlt allerdings noch eine Schärfung der Idee:\\n1. Für wen ist der Deutschland-Stack (DS) gedacht? ÖV, Unternehmen, Privat?\\n2. Aus Sicht eines Software-Herstellers: \\n    * Was sind die konkreten Vorteile, wenn ich mich an den genannten Technologien/Standards orientiere?\\n    * Was ist, wenn ich auf andere Technologien setze? Z.B. nicht Langchain sondern LlamaIndex?\\n    * Kann ich die Aufnahme von alternativen Technologien beantragen? Was sind dann die Aufnahme-Kriterien? Wie wird andererseits verhindert, dass der Stack nicht \"zu breit\" wird?\\n  * Ist geplant, auch regelmäßig zu prüfen, ob z.B. Frameworks auch wieder aus dem Stack rausgenommen werden, weil sie nicht mehr \"on-vogue\" sind?  Da gibt es dann natürlich die Herausforderung, für deprecated-Komponenten die Entfernung rechtzeitig anzukündigen, aber dann auch umzusetzen...\\n\\nViel Erfolg,\\nAndré Gode',\n",
       "  0.019999999552965164,\n",
       "  ['Architektur', 'Beteiligung', 'Plattform', 'Standards', 'Ökosystem'])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select(\"desc_clean\", \"sentiment\", \"labels\").rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4badbd07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
