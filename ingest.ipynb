{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60d97fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.cloud import language_v2\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import utils as u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542e1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "KEYWORDS_VERSION = 1\n",
    "\n",
    "PROJECT_PATH = \"dstack/d-stack-home\"\n",
    "RAW_PATH = \"data/raw_issues.parquet\"\n",
    "CLEANED_PATH = \"data/cleaned_issues.parquet\"\n",
    "ENRICHED_PATH = \"data/issues_enriched.parquet\"\n",
    "LABELED_PATH = \"data/issues_labeled.parquet\"\n",
    "ORG_ATTRIBUTED_PATH = \"data/issues_org_attributed.parquet\"\n",
    "POSTPROCESSED_PATH = \"data/issues_postprocessed.parquet\"\n",
    "KEYWORDS_PATH = f\"keyword_lists/keywords_config_v{KEYWORDS_VERSION}.txt\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "api_key = os.environ.get(\"API_KEY_GCP\")\n",
    "token_vertex = os.environ.get(\"ACCES_TOKEN_VERTEX\")\n",
    "PROJECT_ID = \"project-8415b93b-4a16-4c2b-901\"\n",
    "LOCATION = \"europe-west3\"\n",
    "print(\"API key loaded:\", bool(api_key))\n",
    "client = language_v2.LanguageServiceClient(client_options={\"api_key\": api_key})\n",
    "\n",
    "keywords_path = Path(KEYWORDS_PATH)\n",
    "\n",
    "LABELS = [\n",
    "    line.strip()\n",
    "    for line in keywords_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    if line.strip() and not line.lstrip().startswith(\"#\")\n",
    "]\n",
    "\n",
    "# some iid s to exclude since they predate the feedback process\n",
    "iids_to_exclude = list(range(1,9))\n",
    "columns_to_keep = [\"iid\", \"title\", \"description\", \"state\", \"created_at\", \"updated_at\", \"closed_at\", \"author_id\", \"author_name\", \"author_state\", \"user_notes_count\", \"upvotes\", \"downvotes\", \"references\"]\n",
    "desc_to_exclude = [\"\", \"test\", \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a444e42",
   "metadata": {},
   "source": [
    "### Step 1: Download issues from Open Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = u.fetch_all_gitlab_issues(\"dstack/d-stack-home\")\n",
    "raw_df = pl.DataFrame(issues)\n",
    "raw_df.write_parquet(RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pl.read_parquet(RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = u.clean_issues_df(raw_df, columns_to_keep, iids_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fbb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = u.prepare_issues_df(df_clean, desc_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72023168",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "Move all the expensive additional columns to individual data frames so that we can just join all of them together later, so that each can be rerun individually\n",
    "Each only needs id and computed values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38dc055",
   "metadata": {},
   "source": [
    "## Add sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba791cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text_content: str) -> float:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a single string and returns only the float score.\n",
    "    Returns 0.0 if the input is None or the API call fails.\n",
    "    \"\"\"\n",
    "    if text_content is None:\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        # Create the document object\n",
    "        document = language_v2.Document(\n",
    "            content=text_content, \n",
    "            type_=language_v2.Document.Type.PLAIN_TEXT\n",
    "        )\n",
    "\n",
    "        # Call the API\n",
    "        response = client.analyze_sentiment(document=document)\n",
    "        \n",
    "        # Return the sentiment score (-1.0 to +1.0)\n",
    "        return response.document_sentiment.score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text_content[:20]}... Error: {e}\")\n",
    "        return 0.0 # Return a neutral score on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment = df_prepared.with_columns(\n",
    "    pl.col(\"desc_clean\")\n",
    "      .map_elements(get_sentiment_score, return_dtype=pl.Float64)\n",
    "      .alias(\"sentiment\")\n",
    ")\n",
    "\n",
    "df_with_sentiment.write_parquet(ENRICHED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment = pl.read_parquet(ENRICHED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699ba27",
   "metadata": {},
   "source": [
    "## Add Labels using pre-defined label list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION = (\n",
    "    \"Du bekommst GitLab-Issues aus dem Deutschland-Stack-Konsultationsverfahren. \"\n",
    "    \"Du bist ein Klassifizierungs-Experte. Deine Aufgabe ist es, die Beschreibung zu analysieren \"\n",
    "    \"und sie anhand der Labels in der Liste zu klassifizieren. \"\n",
    "    \"Nutze NUR die zur Verfügung gestellten Labels. Erfinde keine neuen Labels! \"\n",
    "    \"Stelle das Ergebnis als Komma-separierten String zur Verfügung. \"\n",
    "    \"Der String enthält NUR die von dir vergebenen Labels (eins oder bis zu 5). \"\n",
    "    \"Versuche nur so viele Labels wie nötig zu vergeben. \"\n",
    "    \"Wenn kein Label passt, nutze das Label Unklar\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True)\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ffeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_labels(labels_str: str, allowed_labels: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Filtert die durch Komma getrennten Labels und entfernt alle,\n",
    "    die nicht in allowed_labels sind.\n",
    "    \"\"\"\n",
    "    labels = [label.strip() for label in labels_str.split(\",\")]\n",
    "    return [label for label in labels if label in allowed_labels]\n",
    "\n",
    "def classify_issue_multilabel(issue_text: str, labels: list[str]) -> str:\n",
    "    user_prompt = f\"\"\"\n",
    "Labels:\n",
    "{\", \".join(labels)}\n",
    "\n",
    "Issue:\n",
    "{issue_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(text=SYSTEM_INSTRUCTION + \"\\n\\n\" + user_prompt)],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process in batches to handle rate limits and save progress\n",
    "import time\n",
    "\n",
    "batch_size = 10  # Adjust based on rate limits\n",
    "\n",
    "# Check if we have a partial result\n",
    "if Path(LABELED_PATH).exists():\n",
    "    df_labeled = pl.read_parquet(LABELED_PATH)\n",
    "    start_idx = len(df_labeled)\n",
    "else:\n",
    "    df_labeled = df_with_sentiment.clone()\n",
    "    labels_list = [[] for _ in range(len(df_labeled))]\n",
    "    start_idx = 0\n",
    "\n",
    "for i in range(start_idx, len(df_labeled), batch_size):\n",
    "    end_idx = min(i + batch_size, len(df_labeled))\n",
    "    print(f\"Processing batch {i//batch_size + 1}: rows {i} to {end_idx-1}\")\n",
    "\n",
    "    for j in range(end_idx - i):\n",
    "        row_idx = i + j\n",
    "        desc = df_labeled[\"desc_clean\"][row_idx]\n",
    "        try:\n",
    "            labels_str = classify_issue_multilabel(desc, LABELS)\n",
    "            validated_labels = validate_labels(labels_str, LABELS)\n",
    "            labels_list[row_idx] = validated_labels\n",
    "            time.sleep(2)  # Increased sleep to avoid rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {row_idx}: {e}\")\n",
    "            labels_list[row_idx] = []  # Assign empty list on error\n",
    "            time.sleep(5)  # Longer sleep on error\n",
    "\n",
    "    # Update the dataframe with the current labels_list\n",
    "    df_labeled = df_labeled.with_columns(pl.Series(f\"labels_v{KEYWORDS_VERSION}\", labels_list))\n",
    "\n",
    "    # Save progress\n",
    "    df_labeled.write_parquet(LABELED_PATH)\n",
    "    print(f\"Saved progress after batch {i//batch_size + 1}\")\n",
    "\n",
    "print(\"Labeling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4badbd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.write_parquet(LABELED_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b7024",
   "metadata": {},
   "source": [
    "## Add org attribution\n",
    "Usually the author submits the ticket in the name of an organization, e.g. Julia Schöpp for D64. We can probably get most of these organizations from the title / content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postprocessed = pl.read_parquet(POSTPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION = (\n",
    "    \"Du bekommstGitLab-Issues aus dem Deutschland-Stack-Konsultationsverfahren. \"\n",
    "    \"Deine Aufgabe ist es, die Issues einer Organisation zuzuordnen, \"\n",
    "    \"wenn möglich. \"\n",
    "    \"Ordne sie NUR EINER ORGANISATION zu. Erfinde keine neuen Organisationen! \"\n",
    "    \"Stelle das Ergebnis als zur Verfügung. \"\n",
    "    \"Wenn keine Organisation erkennbar ist, antworte mit 'Unklar'. \"\n",
    "    \"Beispiel: \"\n",
    "    \"Konsultationsbeitrag der publicplan GmbH zum Deutschland-Stack \"\n",
    "    \"Deine Antwort: publicplan GmbH\"\n",
    "    \"Beispiel: \"\n",
    "    \"Die Erlang Ecosystem Foundation (EEF)(erlef.org) plädiert für die Inklusion von .... \"\n",
    "    \"Deine Antwort: Erlang Ecosystem Foundation \"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True)\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_issue_org_attribution(issue_title: str, issue_text: str) -> str:\n",
    "    user_prompt = f\"\"\"\n",
    "Titel:\n",
    "{issue_title}\n",
    "\n",
    "Inhalt:\n",
    "{issue_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(text=SYSTEM_INSTRUCTION + \"\\n\\n\" + user_prompt)],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aade82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process as before to add organization attribution\n",
    "\n",
    "# Process in batches to handle rate limits and save progress\n",
    "import time\n",
    "\n",
    "batch_size = 10  # Adjust based on rate limits\n",
    "\n",
    "# Load the labeled dataframe\n",
    "df_labeled = pl.read_parquet(LABELED_PATH)\n",
    "\n",
    "# Check if we have a partial result\n",
    "if Path(ORG_ATTRIBUTED_PATH).exists():\n",
    "    df_org = pl.read_parquet(ORG_ATTRIBUTED_PATH)\n",
    "    if \"org\" in df_org.columns:\n",
    "        org_list = df_org[\"org\"].to_list()\n",
    "    else:\n",
    "        org_list = [\"\"] * len(df_org)\n",
    "    start_idx = len(df_org)\n",
    "else:\n",
    "    df_org = df_labeled.clone()\n",
    "    org_list = [\"\"] * len(df_org)\n",
    "    start_idx = 0\n",
    "\n",
    "for i in range(start_idx, len(df_org), batch_size):\n",
    "    end_idx = min(i + batch_size, len(df_org))\n",
    "    print(f\"Processing batch {i//batch_size + 1}: rows {i} to {end_idx-1}\")\n",
    "\n",
    "    for j in range(end_idx - i):\n",
    "        row_idx = i + j\n",
    "        title = df_org[\"title\"][row_idx]\n",
    "        desc = df_org[\"desc_clean\"][row_idx]\n",
    "        try:\n",
    "            org = add_issue_org_attribution(title, desc)\n",
    "            org_list[row_idx] = org\n",
    "            time.sleep(2)  # Increased sleep to avoid rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {row_idx}: {e}\")\n",
    "            org_list[row_idx] = \"Unklar\"  # Default on error\n",
    "            time.sleep(5)  # Longer sleep on error\n",
    "\n",
    "    # Update the dataframe with the current org_list\n",
    "    df_org = df_org.with_columns(pl.Series(\"org\", org_list))\n",
    "\n",
    "    # Save progress\n",
    "    df_org.write_parquet(ORG_ATTRIBUTED_PATH)\n",
    "    print(f\"Saved progress after batch {i//batch_size + 1}\")\n",
    "\n",
    "print(\"Org attribution completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90909a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org.select(\"title\", \"desc_clean\", \"org\").sample(5).rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52f828",
   "metadata": {},
   "source": [
    "## Postprocess to clean the results a bit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d110608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postprocessed = pl.read_parquet(ORG_ATTRIBUTED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7ab83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postprocessed = u.postprocess_issues(df_postprocessed, label_version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d8573d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postprocessed.write_parquet(f\"{BASE}/processing_date=2025-12-31/issues.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "165b4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postprocessed = df_postprocessed.with_columns(\n",
    "    pl.col(\"created_at\").dt.year().map_elements(\n",
    "        lambda year: 2 if year == 2026 else 1,\n",
    "        return_dtype=pl.Int8\n",
    "    ).alias(\"feedback_round\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f4ee3",
   "metadata": {},
   "source": [
    "## Check for redundant and unassigned labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace23946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get all assigned labels\n",
    "assigned_labels = set(df_postprocessed.select(pl.col(f\"labels_v{KEYWORDS_VERSION}\").explode().unique()).to_series().to_list())\n",
    "\n",
    "# Labels not assigned at all\n",
    "unassigned_labels = [label for label in LABELS if label not in assigned_labels]\n",
    "print(\"Labels not assigned at all:\")\n",
    "print(unassigned_labels)\n",
    "\n",
    "# Compute co-occurrence\n",
    "co_occ = Counter()\n",
    "label_counts = Counter()\n",
    "\n",
    "for row in df_postprocessed.select(f\"labels_v{KEYWORDS_VERSION}\").rows():\n",
    "    labels_in_row = set(row[0])\n",
    "    for label in labels_in_row:\n",
    "        label_counts[label] += 1\n",
    "    for a in labels_in_row:\n",
    "        for b in labels_in_row:\n",
    "            if a < b:\n",
    "                co_occ[(a, b)] += 1\n",
    "\n",
    "# Find labels that mostly occur together (co-occurrence > 80%)\n",
    "mostly_together = []\n",
    "for (a, b), co_count in co_occ.items():\n",
    "    freq_a = label_counts[a]\n",
    "    freq_b = label_counts[b]\n",
    "    pct_a_with_b = co_count / freq_a if freq_a > 0 else 0\n",
    "    pct_b_with_a = co_count / freq_b if freq_b > 0 else 0\n",
    "    if pct_a_with_b > 0.8 and pct_b_with_a > 0.8:\n",
    "        mostly_together.append((a, b, pct_a_with_b, pct_b_with_a))\n",
    "\n",
    "print(\"\\nLabels that mostly occur together (>80% co-occurrence):\")\n",
    "if mostly_together:\n",
    "    for a, b, p1, p2 in mostly_together:\n",
    "        print(f\"{a} and {b}: {p1:.2f} / {p2:.2f}\")\n",
    "else:\n",
    "    print(\"None found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238212e4",
   "metadata": {},
   "source": [
    "### Schema differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132f89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"data/issues_postprocessed\"\n",
    "old_df = pl.read_parquet(f\"{BASE}/processing_date=2025-12-31/issues.parquet\")\n",
    "new_df = pl.read_parquet(f\"{BASE}/processing_date=2026-01-17/issues.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b12f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iid',\n",
       " 'title',\n",
       " 'description',\n",
       " 'state',\n",
       " 'created_at',\n",
       " 'updated_at',\n",
       " 'closed_at',\n",
       " 'author_id',\n",
       " 'author_name',\n",
       " 'author_state',\n",
       " 'user_notes_count',\n",
       " 'upvotes',\n",
       " 'downvotes',\n",
       " 'references',\n",
       " 'desc_clean',\n",
       " 'is_from_form',\n",
       " 'form_page',\n",
       " 'sentiment',\n",
       " 'labels_v1',\n",
       " 'org']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0598f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
